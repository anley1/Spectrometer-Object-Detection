2021-09-12 16:37:17,277 - mmdet - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.7.10 (default, Feb 26 2021, 18:47:35) [GCC 7.3.0]
CUDA available: True
GPU 0: Tesla V100-PCIE-32GB
CUDA_HOME: /usr/local/cuda/10.1/
NVCC: Cuda compilation tools, release 10.1, V10.1.105
GCC: gcc (GCC) 5.4.0
PyTorch: 1.6.0+cu101
PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.5.0 (Git Hash e2ac1fac44c5078ca927cb9b90e1b3066a0b2ed0)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75
  - CuDNN 7.6.3
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

TorchVision: 0.7.0+cu101
OpenCV: 4.5.2
MMCV: 1.2.7
MMCV Compiler: GCC 7.3
MMCV CUDA Compiler: 10.1
MMDetection: 2.11.0+d4c0c18
------------------------------------------------------------

2021-09-12 16:37:17,800 - mmdet - INFO - Distributed training: False
2021-09-12 16:37:18,367 - mmdet - INFO - Config:
dataset_type = 'CocoDataset'
classes = ('beading', )
data_root = 'data/bead_cropped_detection/'
img_norm_cfg = dict(
    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='LoadAnnotations', with_bbox=True, with_mask=True,
        poly2mask=True),
    dict(type='Resize', img_scale=(1333, 800), keep_ratio=True),
    dict(type='RandomFlip', flip_ratio=0.5),
    dict(
        type='Normalize',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        to_rgb=True),
    dict(type='Pad', size_divisor=32),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels', 'gt_masks'])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(1333, 800),
        flip=False,
        transforms=[
            dict(type='Resize', keep_ratio=True),
            dict(type='RandomFlip'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='Pad', size_divisor=32),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ])
]
data = dict(
    samples_per_gpu=1,
    workers_per_gpu=1,
    train=dict(
        type='CocoDataset',
        classes=('beading', ),
        ann_file='data/bead_cropped_detection/traintype2lower.json',
        img_prefix='data/bead_cropped_detection/images/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='LoadAnnotations',
                with_bbox=True,
                with_mask=True,
                poly2mask=True),
            dict(type='Resize', img_scale=(1333, 800), keep_ratio=True),
            dict(type='RandomFlip', flip_ratio=0.5),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='Pad', size_divisor=32),
            dict(type='DefaultFormatBundle'),
            dict(
                type='Collect',
                keys=['img', 'gt_bboxes', 'gt_labels', 'gt_masks'])
        ]),
    val=dict(
        type='CocoDataset',
        classes=('beading', ),
        ann_file='data/bead_cropped_detection/testtype2lower.json',
        img_prefix='data/bead_cropped_detection/images/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(1333, 800),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='Pad', size_divisor=32),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]),
    test=dict(
        type='CocoDataset',
        classes=('beading', ),
        ann_file='data/bead_cropped_detection/testtype2lower.json',
        img_prefix='data/bead_cropped_detection/images/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(1333, 800),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='Pad', size_divisor=32),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]))
evaluation = dict(interval=1, metric=['bbox', 'segm'])
optimizer = dict(type='SGD', lr=0.02, momentum=0.9, weight_decay=0.0001)
optimizer_config = dict(grad_clip=dict(max_norm=35.0, norm_type=2))
lr_config = dict(
    policy='step',
    warmup='linear',
    warmup_iters=500,
    warmup_ratio=0.001,
    step=[24, 27])
runner = dict(type='EpochBasedRunner', max_epochs=30)
checkpoint_config = dict(interval=1, max_keep_ckpts=1)
log_config = dict(
    interval=2,
    hooks=[dict(type='TextLoggerHook'),
           dict(type='TensorboardLoggerHook')])
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = None
resume_from = None
workflow = [('train', 1)]
model = dict(
    type='HybridTaskCascade',
    pretrained='open-mmlab://msra/hrnetv2_w40',
    backbone=dict(
        type='HRNet',
        extra=dict(
            stage1=dict(
                num_modules=1,
                num_branches=1,
                block='BOTTLENECK',
                num_blocks=(4, ),
                num_channels=(64, )),
            stage2=dict(
                num_modules=1,
                num_branches=2,
                block='BASIC',
                num_blocks=(4, 4),
                num_channels=(40, 80)),
            stage3=dict(
                num_modules=4,
                num_branches=3,
                block='BASIC',
                num_blocks=(4, 4, 4),
                num_channels=(40, 80, 160)),
            stage4=dict(
                num_modules=3,
                num_branches=4,
                block='BASIC',
                num_blocks=(4, 4, 4, 4),
                num_channels=(40, 80, 160, 320)))),
    neck=dict(type='HRFPN', in_channels=[40, 80, 160, 320], out_channels=256),
    rpn_head=dict(
        type='RPNHead',
        in_channels=256,
        feat_channels=256,
        anchor_generator=dict(
            type='AnchorGenerator',
            scales=[8],
            ratios=[0.5, 1.0, 2.0],
            strides=[4, 8, 16, 32, 64]),
        bbox_coder=dict(
            type='DeltaXYWHBBoxCoder',
            target_means=[0.0, 0.0, 0.0, 0.0],
            target_stds=[1.0, 1.0, 1.0, 1.0]),
        loss_cls=dict(
            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),
        loss_bbox=dict(
            type='SmoothL1Loss', beta=0.1111111111111111, loss_weight=1.0)),
    roi_head=dict(
        type='HybridTaskCascadeRoIHead',
        interleaved=True,
        mask_info_flow=True,
        num_stages=3,
        stage_loss_weights=[1, 0.5, 0.25],
        bbox_roi_extractor=dict(
            type='SingleRoIExtractor',
            roi_layer=dict(type='RoIAlign', output_size=7, sampling_ratio=0),
            out_channels=256,
            featmap_strides=[4, 8, 16, 32]),
        bbox_head=[
            dict(
                type='Shared2FCBBoxHead',
                in_channels=256,
                fc_out_channels=1024,
                roi_feat_size=7,
                num_classes=2,
                bbox_coder=dict(
                    type='DeltaXYWHBBoxCoder',
                    target_means=[0.0, 0.0, 0.0, 0.0],
                    target_stds=[0.1, 0.1, 0.2, 0.2]),
                reg_class_agnostic=True,
                loss_cls=dict(
                    type='CrossEntropyLoss',
                    use_sigmoid=False,
                    loss_weight=1.0),
                loss_bbox=dict(type='SmoothL1Loss', beta=1.0,
                               loss_weight=1.0)),
            dict(
                type='Shared2FCBBoxHead',
                in_channels=256,
                fc_out_channels=1024,
                roi_feat_size=7,
                num_classes=2,
                bbox_coder=dict(
                    type='DeltaXYWHBBoxCoder',
                    target_means=[0.0, 0.0, 0.0, 0.0],
                    target_stds=[0.05, 0.05, 0.1, 0.1]),
                reg_class_agnostic=True,
                loss_cls=dict(
                    type='CrossEntropyLoss',
                    use_sigmoid=False,
                    loss_weight=1.0),
                loss_bbox=dict(type='SmoothL1Loss', beta=1.0,
                               loss_weight=1.0)),
            dict(
                type='Shared2FCBBoxHead',
                in_channels=256,
                fc_out_channels=1024,
                roi_feat_size=7,
                num_classes=2,
                bbox_coder=dict(
                    type='DeltaXYWHBBoxCoder',
                    target_means=[0.0, 0.0, 0.0, 0.0],
                    target_stds=[0.033, 0.033, 0.067, 0.067]),
                reg_class_agnostic=True,
                loss_cls=dict(
                    type='CrossEntropyLoss',
                    use_sigmoid=False,
                    loss_weight=1.0),
                loss_bbox=dict(type='SmoothL1Loss', beta=1.0, loss_weight=1.0))
        ],
        mask_roi_extractor=dict(
            type='SingleRoIExtractor',
            roi_layer=dict(type='RoIAlign', output_size=14, sampling_ratio=0),
            out_channels=256,
            featmap_strides=[4, 8, 16, 32]),
        mask_head=[
            dict(
                type='HTCMaskHead',
                with_conv_res=False,
                num_convs=4,
                in_channels=256,
                conv_out_channels=256,
                num_classes=2,
                loss_mask=dict(
                    type='CrossEntropyLoss', use_mask=True, loss_weight=1.0)),
            dict(
                type='HTCMaskHead',
                num_convs=4,
                in_channels=256,
                conv_out_channels=256,
                num_classes=2,
                loss_mask=dict(
                    type='CrossEntropyLoss', use_mask=True, loss_weight=1.0)),
            dict(
                type='HTCMaskHead',
                num_convs=4,
                in_channels=256,
                conv_out_channels=256,
                num_classes=2,
                loss_mask=dict(
                    type='CrossEntropyLoss', use_mask=True, loss_weight=1.0))
        ],
        semantic_roi_extractor=dict(
            type='SingleRoIExtractor',
            roi_layer=dict(type='RoIAlign', output_size=14, sampling_ratio=0),
            out_channels=256,
            featmap_strides=[8])),
    train_cfg=dict(
        rpn=dict(
            assigner=dict(
                type='MaxIoUAssigner',
                pos_iou_thr=0.7,
                neg_iou_thr=0.3,
                min_pos_iou=0.3,
                ignore_iof_thr=-1),
            sampler=dict(
                type='RandomSampler',
                num=256,
                pos_fraction=0.5,
                neg_pos_ub=-1,
                add_gt_as_proposals=False),
            allowed_border=0,
            pos_weight=-1,
            debug=False),
        rpn_proposal=dict(
            nms_pre=2000,
            max_per_img=2000,
            nms=dict(type='nms', iou_threshold=0.7),
            min_bbox_size=0),
        rcnn=[
            dict(
                assigner=dict(
                    type='MaxIoUAssigner',
                    pos_iou_thr=0.5,
                    neg_iou_thr=0.5,
                    min_pos_iou=0.5,
                    ignore_iof_thr=-1),
                sampler=dict(
                    type='OHEMSampler',
                    num=512,
                    pos_fraction=0.25,
                    neg_pos_ub=-1,
                    add_gt_as_proposals=True),
                mask_size=28,
                pos_weight=-1,
                debug=False),
            dict(
                assigner=dict(
                    type='MaxIoUAssigner',
                    pos_iou_thr=0.6,
                    neg_iou_thr=0.6,
                    min_pos_iou=0.6,
                    ignore_iof_thr=-1),
                sampler=dict(
                    type='OHEMSampler',
                    num=512,
                    pos_fraction=0.25,
                    neg_pos_ub=-1,
                    add_gt_as_proposals=True),
                mask_size=28,
                pos_weight=-1,
                debug=False),
            dict(
                assigner=dict(
                    type='MaxIoUAssigner',
                    pos_iou_thr=0.7,
                    neg_iou_thr=0.7,
                    min_pos_iou=0.7,
                    ignore_iof_thr=-1),
                sampler=dict(
                    type='OHEMSampler',
                    num=512,
                    pos_fraction=0.25,
                    neg_pos_ub=-1,
                    add_gt_as_proposals=True),
                mask_size=28,
                pos_weight=-1,
                debug=False)
        ]),
    test_cfg=dict(
        rpn=dict(
            nms_pre=1000,
            max_per_img=1000,
            nms=dict(type='nms', iou_threshold=0.7),
            min_bbox_size=0),
        rcnn=dict(
            score_thr=0.001,
            nms=dict(type='nms', iou_threshold=0.3),
            max_per_img=100,
            mask_thr_binary=0.5)))
work_dir = 'freeze/type_2_htc_hrnet'
gpu_ids = range(0, 1)

2021-09-12 16:37:19,279 - mmdet - INFO - load model from: open-mmlab://msra/hrnetv2_w40
2021-09-12 16:37:19,280 - mmdet - INFO - Use load_from_openmmlab loader
2021-09-12 16:37:21,098 - mmdet - WARNING - The model and loaded state dict do not match exactly

unexpected key in source state_dict: incre_modules.0.0.conv1.weight, incre_modules.0.0.bn1.weight, incre_modules.0.0.bn1.bias, incre_modules.0.0.bn1.running_mean, incre_modules.0.0.bn1.running_var, incre_modules.0.0.bn1.num_batches_tracked, incre_modules.0.0.conv2.weight, incre_modules.0.0.bn2.weight, incre_modules.0.0.bn2.bias, incre_modules.0.0.bn2.running_mean, incre_modules.0.0.bn2.running_var, incre_modules.0.0.bn2.num_batches_tracked, incre_modules.0.0.conv3.weight, incre_modules.0.0.bn3.weight, incre_modules.0.0.bn3.bias, incre_modules.0.0.bn3.running_mean, incre_modules.0.0.bn3.running_var, incre_modules.0.0.bn3.num_batches_tracked, incre_modules.0.0.downsample.0.weight, incre_modules.0.0.downsample.1.weight, incre_modules.0.0.downsample.1.bias, incre_modules.0.0.downsample.1.running_mean, incre_modules.0.0.downsample.1.running_var, incre_modules.0.0.downsample.1.num_batches_tracked, incre_modules.1.0.conv1.weight, incre_modules.1.0.bn1.weight, incre_modules.1.0.bn1.bias, incre_modules.1.0.bn1.running_mean, incre_modules.1.0.bn1.running_var, incre_modules.1.0.bn1.num_batches_tracked, incre_modules.1.0.conv2.weight, incre_modules.1.0.bn2.weight, incre_modules.1.0.bn2.bias, incre_modules.1.0.bn2.running_mean, incre_modules.1.0.bn2.running_var, incre_modules.1.0.bn2.num_batches_tracked, incre_modules.1.0.conv3.weight, incre_modules.1.0.bn3.weight, incre_modules.1.0.bn3.bias, incre_modules.1.0.bn3.running_mean, incre_modules.1.0.bn3.running_var, incre_modules.1.0.bn3.num_batches_tracked, incre_modules.1.0.downsample.0.weight, incre_modules.1.0.downsample.1.weight, incre_modules.1.0.downsample.1.bias, incre_modules.1.0.downsample.1.running_mean, incre_modules.1.0.downsample.1.running_var, incre_modules.1.0.downsample.1.num_batches_tracked, incre_modules.2.0.conv1.weight, incre_modules.2.0.bn1.weight, incre_modules.2.0.bn1.bias, incre_modules.2.0.bn1.running_mean, incre_modules.2.0.bn1.running_var, incre_modules.2.0.bn1.num_batches_tracked, incre_modules.2.0.conv2.weight, incre_modules.2.0.bn2.weight, incre_modules.2.0.bn2.bias, incre_modules.2.0.bn2.running_mean, incre_modules.2.0.bn2.running_var, incre_modules.2.0.bn2.num_batches_tracked, incre_modules.2.0.conv3.weight, incre_modules.2.0.bn3.weight, incre_modules.2.0.bn3.bias, incre_modules.2.0.bn3.running_mean, incre_modules.2.0.bn3.running_var, incre_modules.2.0.bn3.num_batches_tracked, incre_modules.2.0.downsample.0.weight, incre_modules.2.0.downsample.1.weight, incre_modules.2.0.downsample.1.bias, incre_modules.2.0.downsample.1.running_mean, incre_modules.2.0.downsample.1.running_var, incre_modules.2.0.downsample.1.num_batches_tracked, incre_modules.3.0.conv1.weight, incre_modules.3.0.bn1.weight, incre_modules.3.0.bn1.bias, incre_modules.3.0.bn1.running_mean, incre_modules.3.0.bn1.running_var, incre_modules.3.0.bn1.num_batches_tracked, incre_modules.3.0.conv2.weight, incre_modules.3.0.bn2.weight, incre_modules.3.0.bn2.bias, incre_modules.3.0.bn2.running_mean, incre_modules.3.0.bn2.running_var, incre_modules.3.0.bn2.num_batches_tracked, incre_modules.3.0.conv3.weight, incre_modules.3.0.bn3.weight, incre_modules.3.0.bn3.bias, incre_modules.3.0.bn3.running_mean, incre_modules.3.0.bn3.running_var, incre_modules.3.0.bn3.num_batches_tracked, incre_modules.3.0.downsample.0.weight, incre_modules.3.0.downsample.1.weight, incre_modules.3.0.downsample.1.bias, incre_modules.3.0.downsample.1.running_mean, incre_modules.3.0.downsample.1.running_var, incre_modules.3.0.downsample.1.num_batches_tracked, downsamp_modules.0.0.weight, downsamp_modules.0.0.bias, downsamp_modules.0.1.weight, downsamp_modules.0.1.bias, downsamp_modules.0.1.running_mean, downsamp_modules.0.1.running_var, downsamp_modules.0.1.num_batches_tracked, downsamp_modules.1.0.weight, downsamp_modules.1.0.bias, downsamp_modules.1.1.weight, downsamp_modules.1.1.bias, downsamp_modules.1.1.running_mean, downsamp_modules.1.1.running_var, downsamp_modules.1.1.num_batches_tracked, downsamp_modules.2.0.weight, downsamp_modules.2.0.bias, downsamp_modules.2.1.weight, downsamp_modules.2.1.bias, downsamp_modules.2.1.running_mean, downsamp_modules.2.1.running_var, downsamp_modules.2.1.num_batches_tracked, final_layer.0.weight, final_layer.0.bias, final_layer.1.weight, final_layer.1.bias, final_layer.1.running_mean, final_layer.1.running_var, final_layer.1.num_batches_tracked, classifier.weight, classifier.bias

2021-09-12 16:37:29,050 - mmdet - INFO - Start running, host: anley1@m3g020, work_dir: /projects/bw83/anley1/Swin-Transformer-Object-Detection/freeze/type_2_htc_hrnet
2021-09-12 16:37:29,051 - mmdet - INFO - workflow: [('train', 1)], max: 30 epochs
apex is not installed
apex is not installed
apex is not installed
apex is not installed
loading annotations into memory...
Done (t=0.09s)
creating index...
index created!
loading annotations into memory...
Done (t=0.01s)
creating index...
index created!
/projects/bw83/anley1/conda_envs/swinEnv/lib/python3.7/site-packages/torch/nn/functional.py:3121: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  "See the documentation of nn.Upsample for details.".format(mode))
2021-09-12 16:37:38,919 - mmdet - INFO - Epoch [1][2/43]	lr: 5.996e-05, eta: 1:14:54, time: 3.489, data_time: 1.624, memory: 5071, loss_rpn_cls: 0.6940, loss_rpn_bbox: 0.2205, s0.loss_cls: 1.1130, s0.acc: 4.4922, s0.loss_bbox: 0.0322, s0.loss_mask: 1.3102, s1.loss_cls: 0.5114, s1.acc: 91.6016, s1.loss_bbox: 0.0015, s1.loss_mask: 0.9695, s2.loss_cls: 0.2915, s2.acc: 4.3945, s2.loss_bbox: 0.0013, s2.loss_mask: 0.9940, loss: 6.1392, grad_norm: 62.2850
2021-09-12 16:37:40,437 - mmdet - INFO - Epoch [1][4/43]	lr: 1.399e-04, eta: 0:45:36, time: 0.766, data_time: 0.105, memory: 5212, loss_rpn_cls: 0.6949, loss_rpn_bbox: 0.1796, s0.loss_cls: 1.0993, s0.acc: 26.9531, s0.loss_bbox: 0.0602, s0.loss_mask: 1.0763, s1.loss_cls: 0.5092, s1.acc: 92.4805, s1.loss_bbox: 0.0027, s1.loss_mask: 0.7794, s2.loss_cls: 0.2879, s2.acc: 5.5664, s2.loss_bbox: 0.0000, s2.loss_mask: 0.9135, loss: 5.6031, grad_norm: 51.7807
2021-09-12 16:37:41,912 - mmdet - INFO - Epoch [1][6/43]	lr: 2.198e-04, eta: 0:35:36, time: 0.738, data_time: 0.103, memory: 5324, loss_rpn_cls: 0.6960, loss_rpn_bbox: 0.1967, s0.loss_cls: 1.0743, s0.acc: 66.4062, s0.loss_bbox: 0.0332, s0.loss_mask: 0.7125, s1.loss_cls: 0.5058, s1.acc: 91.6992, s1.loss_bbox: 0.0099, s1.loss_mask: 0.4870, s2.loss_cls: 0.2850, s2.acc: 8.2031, s2.loss_bbox: 0.0015, s2.loss_mask: 0.5501, loss: 4.5519, grad_norm: 26.9539
2021-09-12 16:37:43,327 - mmdet - INFO - Epoch [1][8/43]	lr: 2.997e-04, eta: 0:30:26, time: 0.708, data_time: 0.043, memory: 5324, loss_rpn_cls: 0.6949, loss_rpn_bbox: 0.1410, s0.loss_cls: 1.0153, s0.acc: 91.6992, s0.loss_bbox: 0.0481, s0.loss_mask: 0.7309, s1.loss_cls: 0.4945, s1.acc: 94.2383, s1.loss_bbox: 0.0028, s1.loss_mask: 0.3143, s2.loss_cls: 0.2782, s2.acc: 15.7227, s2.loss_bbox: 0.0000, s2.loss_mask: 0.2551, loss: 3.9751, grad_norm: 18.8034
2021-09-12 16:37:44,865 - mmdet - INFO - Epoch [1][10/43]	lr: 3.796e-04, eta: 0:27:36, time: 0.769, data_time: 0.128, memory: 5324, loss_rpn_cls: 0.6949, loss_rpn_bbox: 0.1815, s0.loss_cls: 0.9410, s0.acc: 91.2109, s0.loss_bbox: 0.0501, s0.loss_mask: 0.6430, s1.loss_cls: 0.4833, s1.acc: 92.5781, s1.loss_bbox: 0.0059, s1.loss_mask: 0.2804, s2.loss_cls: 0.2678, s2.acc: 64.3555, s2.loss_bbox: 0.0000, s2.loss_mask: 0.1415, loss: 3.6893, grad_norm: 12.1691
2021-09-12 16:37:46,378 - mmdet - INFO - Epoch [1][12/43]	lr: 4.596e-04, eta: 0:25:39, time: 0.756, data_time: 0.098, memory: 5324, loss_rpn_cls: 0.6938, loss_rpn_bbox: 0.1910, s0.loss_cls: 0.8579, s0.acc: 92.2852, s0.loss_bbox: 0.0341, s0.loss_mask: 0.5226, s1.loss_cls: 0.4687, s1.acc: 93.1641, s1.loss_bbox: 0.0029, s1.loss_mask: 0.2747, s2.loss_cls: 0.2598, s2.acc: 87.4023, s2.loss_bbox: 0.0000, s2.loss_mask: 0.1275, loss: 3.4330, grad_norm: 9.1341
2021-09-12 16:37:47,931 - mmdet - INFO - Epoch [1][14/43]	lr: 5.395e-04, eta: 0:24:17, time: 0.770, data_time: 0.103, memory: 5324, loss_rpn_cls: 0.6915, loss_rpn_bbox: 0.1938, s0.loss_cls: 0.7782, s0.acc: 90.7227, s0.loss_bbox: 0.0600, s0.loss_mask: 0.5674, s1.loss_cls: 0.4461, s1.acc: 92.0898, s1.loss_bbox: 0.0162, s1.loss_mask: 0.3209, s2.loss_cls: 0.2510, s2.acc: 91.3086, s2.loss_bbox: 0.0012, s2.loss_mask: 0.1425, loss: 3.4688, grad_norm: 9.4646
2021-09-12 16:37:49,626 - mmdet - INFO - Epoch [1][16/43]	lr: 6.194e-04, eta: 0:23:29, time: 0.854, data_time: 0.135, memory: 5554, loss_rpn_cls: 0.6913, loss_rpn_bbox: 0.1921, s0.loss_cls: 0.6653, s0.acc: 88.2812, s0.loss_bbox: 0.1024, s0.loss_mask: 0.5481, s1.loss_cls: 0.4079, s1.acc: 91.0156, s1.loss_bbox: 0.0175, s1.loss_mask: 0.3003, s2.loss_cls: 0.2374, s2.acc: 91.4062, s2.loss_bbox: 0.0024, s2.loss_mask: 0.1361, loss: 3.3007, grad_norm: 7.6892
2021-09-12 16:37:51,006 - mmdet - INFO - Epoch [1][18/43]	lr: 6.993e-04, eta: 0:22:28, time: 0.690, data_time: 0.066, memory: 5554, loss_rpn_cls: 0.6899, loss_rpn_bbox: 0.2030, s0.loss_cls: 0.5247, s0.acc: 90.8203, s0.loss_bbox: 0.0589, s0.loss_mask: 0.5554, s1.loss_cls: 0.3598, s1.acc: 92.2852, s1.loss_bbox: 0.0259, s1.loss_mask: 0.2812, s2.loss_cls: 0.2225, s2.acc: 92.9688, s2.loss_bbox: 0.0056, s2.loss_mask: 0.1424, loss: 3.0693, grad_norm: 7.8155
2021-09-12 16:37:52,363 - mmdet - INFO - Epoch [1][20/43]	lr: 7.792e-04, eta: 0:21:37, time: 0.678, data_time: 0.052, memory: 5554, loss_rpn_cls: 0.6887, loss_rpn_bbox: 0.2172, s0.loss_cls: 0.4514, s0.acc: 90.9180, s0.loss_bbox: 0.0617, s0.loss_mask: 0.4986, s1.loss_cls: 0.3134, s1.acc: 92.4805, s1.loss_bbox: 0.0213, s1.loss_mask: 0.2343, s2.loss_cls: 0.2063, s2.acc: 93.1641, s2.loss_bbox: 0.0035, s2.loss_mask: 0.1158, loss: 2.8123, grad_norm: 6.8235
2021-09-12 16:37:53,735 - mmdet - INFO - Epoch [1][22/43]	lr: 8.592e-04, eta: 0:20:56, time: 0.679, data_time: 0.054, memory: 5554, loss_rpn_cls: 0.6872, loss_rpn_bbox: 0.1896, s0.loss_cls: 0.4331, s0.acc: 91.2109, s0.loss_bbox: 0.0761, s0.loss_mask: 0.4854, s1.loss_cls: 0.2609, s1.acc: 93.2617, s1.loss_bbox: 0.0166, s1.loss_mask: 0.2365, s2.loss_cls: 0.1876, s2.acc: 93.8477, s2.loss_bbox: 0.0029, s2.loss_mask: 0.1236, loss: 2.6995, grad_norm: 4.9506
2021-09-12 16:37:55,080 - mmdet - INFO - Epoch [1][24/43]	lr: 9.391e-04, eta: 0:20:21, time: 0.679, data_time: 0.073, memory: 5554, loss_rpn_cls: 0.6883, loss_rpn_bbox: 0.2087, s0.loss_cls: 0.4587, s0.acc: 91.4062, s0.loss_bbox: 0.0660, s0.loss_mask: 0.5383, s1.loss_cls: 0.2363, s1.acc: 93.0664, s1.loss_bbox: 0.0188, s1.loss_mask: 0.2443, s2.loss_cls: 0.1754, s2.acc: 93.8477, s2.loss_bbox: 0.0000, s2.loss_mask: 0.1176, loss: 2.7523, grad_norm: 8.5744
2021-09-12 16:37:56,404 - mmdet - INFO - Epoch [1][26/43]	lr: 1.019e-03, eta: 0:19:49, time: 0.662, data_time: 0.048, memory: 5554, loss_rpn_cls: 0.6886, loss_rpn_bbox: 0.1294, s0.loss_cls: 0.3347, s0.acc: 93.8477, s0.loss_bbox: 0.0385, s0.loss_mask: 0.4636, s1.loss_cls: 0.1861, s1.acc: 94.9219, s1.loss_bbox: 0.0101, s1.loss_mask: 0.2186, s2.loss_cls: 0.1555, s2.acc: 95.1172, s2.loss_bbox: 0.0039, s2.loss_mask: 0.1109, loss: 2.3400, grad_norm: 11.2459
2021-09-12 16:37:57,828 - mmdet - INFO - Epoch [1][28/43]	lr: 1.099e-03, eta: 0:19:27, time: 0.712, data_time: 0.075, memory: 5554, loss_rpn_cls: 0.6798, loss_rpn_bbox: 0.1510, s0.loss_cls: 0.4350, s0.acc: 90.9180, s0.loss_bbox: 0.0550, s0.loss_mask: 0.4617, s1.loss_cls: 0.1945, s1.acc: 92.2852, s1.loss_bbox: 0.0229, s1.loss_mask: 0.2335, s2.loss_cls: 0.1312, s2.acc: 93.0664, s2.loss_bbox: 0.0029, s2.loss_mask: 0.1076, loss: 2.4750, grad_norm: 9.6312
2021-09-12 16:37:59,176 - mmdet - INFO - Epoch [1][30/43]	lr: 1.179e-03, eta: 0:19:04, time: 0.674, data_time: 0.098, memory: 5554, loss_rpn_cls: 0.6818, loss_rpn_bbox: 0.1951, s0.loss_cls: 0.2938, s0.acc: 92.5781, s0.loss_bbox: 0.0085, s0.loss_mask: 0.4000, s1.loss_cls: 0.1492, s1.acc: 92.7734, s1.loss_bbox: 0.0034, s1.loss_mask: 0.2100, s2.loss_cls: 0.0913, s2.acc: 92.9688, s2.loss_bbox: 0.0000, s2.loss_mask: 0.1025, loss: 2.1357, grad_norm: 6.2215
2021-09-12 16:38:00,714 - mmdet - INFO - Epoch [1][32/43]	lr: 1.259e-03, eta: 0:18:51, time: 0.769, data_time: 0.108, memory: 5554, loss_rpn_cls: 0.6787, loss_rpn_bbox: 0.1387, s0.loss_cls: 0.2535, s0.acc: 92.5781, s0.loss_bbox: 0.0098, s0.loss_mask: 0.3985, s1.loss_cls: 0.1313, s1.acc: 92.8711, s1.loss_bbox: 0.0000, s1.loss_mask: 0.2061, s2.loss_cls: 0.0744, s2.acc: 92.8711, s2.loss_bbox: 0.0000, s2.loss_mask: 0.0994, loss: 1.9905, grad_norm: 5.8904
2021-09-12 16:38:02,077 - mmdet - INFO - Epoch [1][34/43]	lr: 1.339e-03, eta: 0:18:33, time: 0.682, data_time: 0.077, memory: 5554, loss_rpn_cls: 0.6799, loss_rpn_bbox: 0.2265, s0.loss_cls: 0.2241, s0.acc: 92.7734, s0.loss_bbox: 0.0003, s0.loss_mask: 0.3474, s1.loss_cls: 0.1206, s1.acc: 92.7734, s1.loss_bbox: 0.0000, s1.loss_mask: 0.1858, s2.loss_cls: 0.0657, s2.acc: 92.7734, s2.loss_bbox: 0.0000, s2.loss_mask: 0.0926, loss: 1.9430, grad_norm: 5.3386
2021-09-12 16:38:03,326 - mmdet - INFO - Epoch [1][36/43]	lr: 1.419e-03, eta: 0:18:13, time: 0.625, data_time: 0.046, memory: 5554, loss_rpn_cls: 0.6818, loss_rpn_bbox: 0.1323, s0.loss_cls: 0.1775, s0.acc: 94.2383, s0.loss_bbox: 0.0002, s0.loss_mask: 0.3673, s1.loss_cls: 0.0956, s1.acc: 94.2383, s1.loss_bbox: 0.0000, s1.loss_mask: 0.1991, s2.loss_cls: 0.0499, s2.acc: 94.2383, s2.loss_bbox: 0.0000, s2.loss_mask: 0.0989, loss: 1.8027, grad_norm: 5.1210
2021-09-12 16:38:04,549 - mmdet - INFO - Epoch [1][38/43]	lr: 1.499e-03, eta: 0:17:54, time: 0.611, data_time: 0.053, memory: 5554, loss_rpn_cls: 0.6725, loss_rpn_bbox: 0.1800, s0.loss_cls: 0.1525, s0.acc: 94.1406, s0.loss_bbox: 0.0002, s0.loss_mask: 0.3590, s1.loss_cls: 0.0885, s1.acc: 94.1406, s1.loss_bbox: 0.0000, s1.loss_mask: 0.1823, s2.loss_cls: 0.0440, s2.acc: 94.1406, s2.loss_bbox: 0.0000, s2.loss_mask: 0.0958, loss: 1.7748, grad_norm: 7.1157
2021-09-12 16:38:05,802 - mmdet - INFO - Epoch [1][40/43]	lr: 1.578e-03, eta: 0:17:38, time: 0.627, data_time: 0.052, memory: 5561, loss_rpn_cls: 0.6718, loss_rpn_bbox: 0.1873, s0.loss_cls: 0.1196, s0.acc: 93.7500, s0.loss_bbox: 0.0001, s0.loss_mask: 0.3443, s1.loss_cls: 0.0779, s1.acc: 93.7500, s1.loss_bbox: 0.0000, s1.loss_mask: 0.1737, s2.loss_cls: 0.0404, s2.acc: 93.7500, s2.loss_bbox: 0.0000, s2.loss_mask: 0.0913, loss: 1.7063, grad_norm: 4.7173
2021-09-12 16:38:06,903 - mmdet - INFO - Epoch [1][42/43]	lr: 1.658e-03, eta: 0:17:19, time: 0.551, data_time: 0.047, memory: 5561, loss_rpn_cls: 0.6689, loss_rpn_bbox: 0.1686, s0.loss_cls: 0.0915, s0.acc: 94.3359, s0.loss_bbox: 0.0001, s0.loss_mask: 0.3615, s1.loss_cls: 0.0601, s1.acc: 94.3359, s1.loss_bbox: 0.0000, s1.loss_mask: 0.1841, s2.loss_cls: 0.0335, s2.acc: 94.3359, s2.loss_bbox: 0.0000, s2.loss_mask: 0.0962, loss: 1.6645, grad_norm: 5.6616
2021-09-12 16:38:07,397 - mmdet - INFO - Saving checkpoint at 1 epochs
[                                                  ] 0/8, elapsed: 0s, ETA:[>>>>                               ] 1/8, 1.6 task/s, elapsed: 1s, ETA:     4s[>>>>>>>>                           ] 2/8, 2.5 task/s, elapsed: 1s, ETA:     2s[>>>>>>>>>>>>>                      ] 3/8, 3.1 task/s, elapsed: 1s, ETA:     2s[>>>>>>>>>>>>>>>>>                  ] 4/8, 3.5 task/s, elapsed: 1s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>              ] 5/8, 3.9 task/s, elapsed: 1s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>         ] 6/8, 4.1 task/s, elapsed: 1s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>     ] 7/8, 4.4 task/s, elapsed: 2s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 8/8, 4.7 task/s, elapsed: 2s, ETA:     0sTraceback (most recent call last):
  File "tools/train.py", line 188, in <module>
    main()
  File "tools/train.py", line 183, in main
    meta=meta)
  File "/projects/bw83/anley1/Swin-Transformer-Object-Detection/mmdet/apis/train.py", line 185, in train_detector
    runner.run(data_loaders, cfg.workflow)
  File "/projects/bw83/anley1/conda_envs/swinEnv/lib/python3.7/site-packages/mmcv/runner/epoch_based_runner.py", line 125, in run
    epoch_runner(data_loaders[i], **kwargs)
  File "/projects/bw83/anley1/conda_envs/swinEnv/lib/python3.7/site-packages/mmcv/runner/epoch_based_runner.py", line 54, in train
    self.call_hook('after_train_epoch')
  File "/projects/bw83/anley1/conda_envs/swinEnv/lib/python3.7/site-packages/mmcv/runner/base_runner.py", line 308, in call_hook
    getattr(hook, fn_name)(self)
  File "/projects/bw83/anley1/Swin-Transformer-Object-Detection/mmdet/core/evaluation/eval_hooks.py", line 147, in after_train_epoch
    key_score = self.evaluate(runner, results)
  File "/projects/bw83/anley1/Swin-Transformer-Object-Detection/mmdet/core/evaluation/eval_hooks.py", line 177, in evaluate
    results, logger=runner.logger, **self.eval_kwargs)
  File "/projects/bw83/anley1/Swin-Transformer-Object-Detection/mmdet/datasets/coco.py", line 417, in evaluate
    result_files, tmp_dir = self.format_results(results, jsonfile_prefix)
  File "/projects/bw83/anley1/Swin-Transformer-Object-Detection/mmdet/datasets/coco.py", line 362, in format_results
    result_files = self.results2json(results, jsonfile_prefix)
  File "/projects/bw83/anley1/Swin-Transformer-Object-Detection/mmdet/datasets/coco.py", line 299, in results2json
    json_results = self._segm2json(results)
  File "/projects/bw83/anley1/Swin-Transformer-Object-Detection/mmdet/datasets/coco.py", line 250, in _segm2json
    data['category_id'] = self.cat_ids[label]
IndexError: list index out of range
